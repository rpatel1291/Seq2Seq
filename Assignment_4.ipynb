{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DLC-ltNHo7SM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 4: Build A Seq2Seq Model For Machine Translation\n",
        "### Name: Ravi Patel | CWID: 10432313 | Date: 4/29/2019\n",
        "### Task: Translate English to "
      ]
    },
    {
      "metadata": {
        "id": "hL_yTPQdqmqO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preparation\n",
        "### 1.1 Load And Clean Text"
      ]
    },
    {
      "metadata": {
        "id": "sYCWVtMIowXu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re, string, numpy\n",
        "from unicodedata import normalize\n",
        "\n",
        "def load_doc(filename):\n",
        "    '''\n",
        "        load doc into memory\n",
        "        open file as read only -> read all text -> close file\n",
        "        return text\n",
        "    '''\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "def to_pairs(doc):\n",
        "    '''\n",
        "        split a loaded document into sentences\n",
        "    '''\n",
        "    line = doc.strip().split('n')\n",
        "    pairs = [line.split('\\t') for line in lines]\n",
        "    return pairs\n",
        "\n",
        "def clean_data(lines):\n",
        "    cleaned = list()\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    for pairs in lines:\n",
        "        clean_pair = list()\n",
        "        for line in pair:\n",
        "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "            line = line.decode('UTF-8')\n",
        "            line = line.split()\n",
        "            line = [word.lower() for word in line]\n",
        "            line = [word.translate(table) for word in line]\n",
        "            line = [re_print.sub('',w) for w in line]\n",
        "            line = [word for word in line if word.isalpha()]\n",
        "            cleaned.append(clean_pair)\n",
        "        cleaned.append(clean_pair)\n",
        "    return numpy.array(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iF2VHT3jwg4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = #Filename\n",
        "\n",
        "n_train = # number of sentences are you foung to use for training?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tEgC2w6ixXdG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc = load_doc(filename)\n",
        "pairs = to_pairs(doc)\n",
        "clean_pairs = clean_data(pairs)[0:n_train, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9HlcBMczTAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(3000, 3010):\n",
        "    print('['+clean_pairs[i,0]+ '] => ['+ clean_pairs[i,1]+']')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6TTpUza519Td",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_texts = clean_pairs[0:]\n",
        "target_text = ['\\t' + text + '\\n' for text in clean_pairs[:,1]]\n",
        "\n",
        "print('Length of input_texts: '+ str(input_text.shape))\n",
        "print('Length of target_texts: ' + str(target_texts.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYL9JeY1-BtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
        "max_decoder_seq_length = max(len(line) for line in target_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZFeNfYW_k9U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Text Processing\n",
        "###2.1 Convert Texts To Sequences"
      ]
    },
    {
      "metadata": {
        "id": "WCDqwNuDCbgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def text2sequences(max_len, lines):\n",
        "    tokenizer = Tokenizer(char_level=True, filters='')\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    seqs = tokenizer.texts_to_sequences(lines)\n",
        "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
        "    return seqs_pad, tokenizer.word_index\n",
        "\n",
        "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, input_texts)\n",
        "decoder_input_seq, target_token_index = text2sequences(max_encoder_seq_length, target_texts)\n",
        "\n",
        "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
        "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
        "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
        "print('shape of target_token_index: ' + str(len(target_token_index)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OVImF7U2G20W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_encoder_tokens = len(input_token_index) + 1\n",
        "num_decoder_tokens = len(target_token_index) + 1\n",
        "\n",
        "print('num_encoder_token: ' + str(num_encoder_tokens))\n",
        "print('num_decoder_token: ' + str(num_decoder_tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hl7svBUiHkQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_texts[100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbArv0GdHmyR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_input_seq[100,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4D2GS7CH3H7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###2.2 One-Hot Encode"
      ]
    },
    {
      "metadata": {
        "id": "ZnJ-GU23IB8F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "def onehot_encode(sequence, max_len, vocab_size):\n",
        "    n = len(sequences)\n",
        "    data = numpy.zeros((n, max_len, vocab_size))\n",
        "    for i in range(n):\n",
        "        data[i,:,:] = to_categorical(sequences[i], num_classes=vocab_size)\n",
        "    return data\n",
        "\n",
        "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
        "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
        "\n",
        "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
        "decoder_target_seq[:, 0:-1] = decoder_input_seq[:,1:]\n",
        "decoder_target_data = onehot_encode(decoder_target_seq, max_decoder_seq_length, num_decoder_tokens)\n",
        "\n",
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1iisYjrtRyn6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Build The Network For Training\n",
        "###3.1 Encoder Network"
      ]
    },
    {
      "metadata": {
        "id": "0-oIYDPiR-8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, LSTM\n",
        "from keras.models import Model\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_inputs')\n",
        "\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True,\n",
        "                    dropout=0.5, name='encoder_inputs')\n",
        "\n",
        "_,state_h,state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "encoder_model = Model(inputs = encoder_inputs, outputs=[state_h, state_c], name='encoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NZOcu3HuU0zq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "\n",
        "SVG(model_to_dot(encoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
        "\n",
        "plot_model(model=encoder_model,\n",
        "          show_shapes=False,\n",
        "          to_file='encoder.pdf')\n",
        "\n",
        "encoder_model.summary()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHiM0193W5G4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###3.2 Decoder Network"
      ]
    },
    {
      "metadata": {
        "id": "_eWNT68EW-c9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "decoder_input_h = Input(shape=(latent_dim,), name='decoder_input_h')\n",
        "decoder_input_c = Input(shape=(latent_dim,), name='decoder_input_c')\n",
        "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5, name='decode_lstm')\n",
        "\n",
        "decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_input_x, initial_state=[decoder_input_h, decoder_input_c])\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
        "\n",
        "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c], outputs=[decoder_outputs,state_h, state_c],\n",
        "                     name='decoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CRB_FJKVb8rf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "\n",
        "SVG(model_to_dot(decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
        "\n",
        "plot_model(model=decoder_model, show_shapes=False, to_file='decoder.pdf')\n",
        "\n",
        "decoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLu7VE2Wdl3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###3.3 Connect The Encoder And Decoder"
      ]
    },
    {
      "metadata": {
        "id": "fGt-OKHQdzD2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
        "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
        "\n",
        "encoder_final_states = encoder_model([encoder_input_x])\n",
        "decoder_lstm_output, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_final_states)\n",
        "decoder_pred = decoder_dense(decoder_lstm_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input_x, decoder_input_x],\n",
        "             outputs = decoder_pred,\n",
        "             name='model_training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OrSIIQMnnbUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(state_h)\n",
        "print(decoder_input_h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mf86zjyanfCl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='avg'))\n",
        "\n",
        "plot_model( model=model, show_shapes=False,\n",
        "          to_file='model_training.pdf')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKL6TzaAo1Nb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###3.5 Fit The Model On the Bilingual Dataset"
      ]
    },
    {
      "metadata": {
        "id": "3nWpox3CpSrX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('shape of encoder_input_data' + str(encoder_input_data.shape))\n",
        "print('shape of decoder_input_data' + str(decoder_input_data.shape))\n",
        "print('shape of decoder_target_data' + str(decoder_target_data.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvF3I_9vsdTy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "model.fit([encoder_input_data, decoder_input_data], \n",
        "          decoder_target_data,\n",
        "         batch_size=64,\n",
        "         epochs=50,\n",
        "         validation_split=0.2)\n",
        "\n",
        "model.save('seq2seq.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "heo2pSQSuGwV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##4. Make Prediction\n",
        "###4.1 Translate English to "
      ]
    },
    {
      "metadata": {
        "id": "YBltt46at5F-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reverse_input_char_index = dict((i,char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i,char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BRSLqwA_vfF9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encode_model.predict(input_seq)\n",
        "    \n",
        "    target_seq = numpy.zeros((1,1, num_decoder_token))\n",
        "    target[0,0,target_token_index['\\t']] = 1\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        \n",
        "        sampled_token_index = numpy.argmax(output_token_index[0,-1,:])\n",
        "        \n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "        \n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        \n",
        "        target_seq = numpy.zeros((1,1,num_decoder_tokens))\n",
        "        target_seq[0,0, sampled_token_index] = 1\n",
        "        \n",
        "        states_value = [h,c]\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m0ijFZMNAfr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for seq_index in range(2100, 2120):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    \n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('English: \\t ', input_texts[seq_index])\n",
        "    print(' (true): \\t ', target_texts[seq_index][1:-1])\n",
        "    print(' (pred): \\t ', decoded_sentence[0:-1])\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwId3qt-CaP0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###4.2 Translate An English Sentence To The Target Language"
      ]
    },
    {
      "metadata": {
        "id": "FERu-TONDE-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_setence = 'why is that'\n",
        "\n",
        "'''\n",
        "   input_setence = do tokenization\n",
        "   input_x = do one-hot encode\n",
        "   translated_sentence = do translation\n",
        "'''\n",
        "\n",
        "print('source sentence is: ' + input_sentence)\n",
        "print('translated sentence is: ' + translated_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}