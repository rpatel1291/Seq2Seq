{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLC-ltNHo7SM"
   },
   "source": [
    "# Homework 4: Build A Seq2Seq Model For Machine Translation\n",
    "### Name: Ravi Patel | CWID: 10432313 | Date: 4/29/2019\n",
    "### Task: Translate English to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hL_yTPQdqmqO"
   },
   "source": [
    "## 1. Data Preparation\n",
    "### 1.1 Load And Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYCWVtMIowXu"
   },
   "outputs": [],
   "source": [
    "import re, string, numpy\n",
    "from unicodedata import normalize\n",
    "\n",
    "def load_doc(filename):\n",
    "    '''\n",
    "        load doc into memory\n",
    "        open file as read only -> read all text -> close file\n",
    "        return text\n",
    "    '''\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def to_pairs(doc):\n",
    "    '''\n",
    "        split a loaded document into sentences\n",
    "    '''\n",
    "    line = doc.strip().split('n')\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    for pairs in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            line = line.split()\n",
    "            line = [word.lower() for word in line]\n",
    "            line = [word.translate(table) for word in line]\n",
    "            line = [re_print.sub('',w) for w in line]\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            cleaned.append(clean_pair)\n",
    "        cleaned.append(clean_pair)\n",
    "    return numpy.array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iF2VHT3jwg4u"
   },
   "outputs": [],
   "source": [
    "filename = \"./Data/hin.txt\"\n",
    "\n",
    "n_train = 20000 # number of sentences are you foung to use for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tEgC2w6ixXdG"
   },
   "outputs": [],
   "source": [
    "doc = load_doc(filename)\n",
    "pairs = to_pairs(doc)\n",
    "clean_pairs = clean_data(pairs)[0:n_train, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9HlcBMczTAW"
   },
   "outputs": [],
   "source": [
    "for i in range(3000, 3010):\n",
    "    print('['+clean_pairs[i,0]+ '] => ['+ clean_pairs[i,1]+']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TTpUza519Td"
   },
   "outputs": [],
   "source": [
    "input_texts = clean_pairs[0:]\n",
    "target_text = ['\\t' + text + '\\n' for text in clean_pairs[:,1]]\n",
    "\n",
    "print('Length of input_texts: '+ str(input_text.shape))\n",
    "print('Length of target_texts: ' + str(target_texts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYL9JeY1-BtU"
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
    "max_decoder_seq_length = max(len(line) for line in target_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZFeNfYW_k9U"
   },
   "source": [
    "## 2. Text Processing\n",
    "###2.1 Convert Texts To Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCDqwNuDCbgS"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer(char_level=True, filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index\n",
    "\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, input_texts)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_encoder_seq_length, target_texts)\n",
    "\n",
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVImF7U2G20W"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(input_token_index) + 1\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "print('num_encoder_token: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_token: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hl7svBUiHkQI"
   },
   "outputs": [],
   "source": [
    "target_texts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbArv0GdHmyR"
   },
   "outputs": [],
   "source": [
    "decoder_input_seq[100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4D2GS7CH3H7"
   },
   "source": [
    "###2.2 One-Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnJ-GU23IB8F"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def onehot_encode(sequence, max_len, vocab_size):\n",
    "    n = len(sequences)\n",
    "    data = numpy.zeros((n, max_len, vocab_size))\n",
    "    for i in range(n):\n",
    "        data[i,:,:] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "    return data\n",
    "\n",
    "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
    "decoder_target_seq[:, 0:-1] = decoder_input_seq[:,1:]\n",
    "decoder_target_data = onehot_encode(decoder_target_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iisYjrtRyn6"
   },
   "source": [
    "## 3. Build The Network For Training\n",
    "###3.1 Encoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-oIYDPiR-8K"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_inputs')\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True,\n",
    "                    dropout=0.5, name='encoder_inputs')\n",
    "\n",
    "_,state_h,state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs=[state_h, state_c], name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZOcu3HuU0zq"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(encoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(model=encoder_model,\n",
    "          show_shapes=False,\n",
    "          to_file='encoder.pdf')\n",
    "\n",
    "encoder_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FHiM0193W5G4"
   },
   "source": [
    "###3.2 Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eWNT68EW-c9"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "decoder_input_h = Input(shape=(latent_dim,), name='decoder_input_h')\n",
    "decoder_input_c = Input(shape=(latent_dim,), name='decoder_input_c')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5, name='decode_lstm')\n",
    "\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_input_x, initial_state=[decoder_input_h, decoder_input_c])\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c], outputs=[decoder_outputs,state_h, state_c],\n",
    "                     name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRB_FJKVb8rf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(model=decoder_model, show_shapes=False, to_file='decoder.pdf')\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLu7VE2Wdl3B"
   },
   "source": [
    "###3.3 Connect The Encoder And Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGt-OKHQdzD2"
   },
   "outputs": [],
   "source": [
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "encoder_final_states = encoder_model([encoder_input_x])\n",
    "decoder_lstm_output, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_final_states)\n",
    "decoder_pred = decoder_dense(decoder_lstm_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x],\n",
    "             outputs = decoder_pred,\n",
    "             name='model_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrSIIQMnnbUN"
   },
   "outputs": [],
   "source": [
    "print(state_h)\n",
    "print(decoder_input_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mf86zjyanfCl"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='avg'))\n",
    "\n",
    "plot_model( model=model, show_shapes=False,\n",
    "          to_file='model_training.pdf')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKL6TzaAo1Nb"
   },
   "source": [
    "###3.5 Fit The Model On the Bilingual Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nWpox3CpSrX"
   },
   "outputs": [],
   "source": [
    "print('shape of encoder_input_data' + str(encoder_input_data.shape))\n",
    "print('shape of decoder_input_data' + str(decoder_input_data.shape))\n",
    "print('shape of decoder_target_data' + str(decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvF3I_9vsdTy"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], \n",
    "          decoder_target_data,\n",
    "         batch_size=64,\n",
    "         epochs=50,\n",
    "         validation_split=0.2)\n",
    "\n",
    "model.save('seq2seq.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "heo2pSQSuGwV"
   },
   "source": [
    "##4. Make Prediction\n",
    "###4.1 Translate English to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBltt46at5F-"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i,char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i,char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRSLqwA_vfF9"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encode_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = numpy.zeros((1,1, num_decoder_token))\n",
    "    target[0,0,target_token_index['\\t']] = 1\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = numpy.argmax(output_token_index[0,-1,:])\n",
    "        \n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = numpy.zeros((1,1,num_decoder_tokens))\n",
    "        target_seq[0,0, sampled_token_index] = 1\n",
    "        \n",
    "        states_value = [h,c]\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0ijFZMNAfr3"
   },
   "outputs": [],
   "source": [
    "for seq_index in range(2100, 2120):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    \n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('English: \\t ', input_texts[seq_index])\n",
    "    print(' (true): \\t ', target_texts[seq_index][1:-1])\n",
    "    print(' (pred): \\t ', decoded_sentence[0:-1])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwId3qt-CaP0"
   },
   "source": [
    "###4.2 Translate An English Sentence To The Target Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FERu-TONDE-k"
   },
   "outputs": [],
   "source": [
    "input_setence = 'why is that'\n",
    "\n",
    "'''\n",
    "   input_setence = do tokenization\n",
    "   input_x = do one-hot encode\n",
    "   translated_sentence = do translation\n",
    "'''\n",
    "\n",
    "print('source sentence is: ' + input_sentence)\n",
    "print('translated sentence is: ' + translated_sentence)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
